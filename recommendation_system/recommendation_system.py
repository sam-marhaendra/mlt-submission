# -*- coding: utf-8 -*-
"""recommendation_system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DzFpNWL8v_oeo8VM5SJ84HMnpnxemljF

# **Food Recommendation System**

**Dataset source: https://www.kaggle.com/datasets/schemersays/food-recommendation-system**

# **Preparation**
"""

!pip install kaggle

!mkdir -p ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d schemersays/food-recommendation-system

!unzip /content/food-recommendation-system.zip

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# libraries for content-based filtering
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# libraries for collaborative filtering
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ReduceLROnPlateau

import warnings
warnings.filterwarnings("ignore")

df_foods = pd.read_csv('/content/1662574418893344.csv')
df_ratings = pd.read_csv('/content/ratings.csv')

"""# **Data Understanding**

### **`df_foods`**
"""

df_foods.head(3)

df_foods.shape

df_foods.info()

print(len(df_foods['C_Type'].unique()))
print(df_foods['C_Type'].unique())

df_foods['C_Type'] = df_foods['C_Type'].replace([' Korean'], 'Korean')

print(len(df_foods['C_Type'].unique()))
print(df_foods['C_Type'].unique())

df_foods['C_Type'].value_counts().sort_values()

# Distribution plot of data about food types
df_foods['C_Type'].value_counts().sort_values().plot(kind='barh')

"""### **`df_ratings`**"""

df_ratings.head(3)

df_ratings.shape

df_ratings.info()

print('Count of `User_ID`: ', len(df_ratings['User_ID'].unique()))
print('Count of `Food_ID`: ', len(df_ratings['Food_ID'].unique()))

df_ratings.describe()

# Distribution plot of data about rating
sns.displot(df_ratings['Rating'], kde=True, bins=10)

"""# **Data Preprocessing**"""

all_food_rate = df_ratings
all_food_rate

# Merge dataframe `all_food_rate` and dataframe `df_foods` based on `Food_ID` column
all_food = pd.merge(all_food_rate,
                    df_foods[['Food_ID', 'Name', 'C_Type']],
                    on='Food_ID',
                    how='left')

all_food

"""# **Data Preparation**"""

# Check for missing value on dataframe `all_food`
all_food.isnull().sum()

# Removing missing value on dataframe `all_food`
all_food = all_food.dropna()
all_food

# Check for missing value on dataframe `df_ratings`
df_ratings.isnull().sum()

# Removing missing value on dataframe `df_ratings`
df_ratings = df_ratings.dropna()
df_ratings

# Sort data based on `Food_ID` column
fix_food = all_food.sort_values('Food_ID', ascending=True)
fix_food

len(fix_food['Food_ID'].unique())

fix_food['C_Type'].unique()

preparation = fix_food
preparation.sort_values('Food_ID')

# Removing duplicate rows based on `Food_ID` column
preparation = preparation.drop_duplicates('Food_ID')
preparation

preparation['C_Type'][preparation['C_Type'] == 'Healthy Food'] = 'Healthy_Food'

# Converting `Food_ID`, `Name`, and `C_Type` series into list
food_id = preparation['Food_ID'].tolist()
food_name = preparation['Name'].tolist()
food_category = preparation['C_Type'].tolist()

print(len(food_id))
print(len(food_name))
print(len(food_category))

# Creating dictionary for `food_id`, `food_name`, and `food_category`
food_new = pd.DataFrame({
    'id': food_id,
    'food_name': food_name,
    'category': food_category
})

food_new

"""# **Modeling**

## **1. Content-Based Filtering**
"""

data = food_new
data.sample(5)

# TfidfVectorizer initialization
tf = TfidfVectorizer()

# Determining idf on the food types
tf.fit(data['category'])

# Mapping array from integer index feature to name feature
tf.get_feature_names_out()

# Doing fit_transform into matrix form
tfidf_matrix = tf.fit_transform(data['category'])

# Check tf-idf matrix
tfidf_matrix.shape

# Changing tf-idf vector into matrix using todense() function
tfidf_matrix.todense()

"""
  Create dataframe to see tf-idf matrix
  Column filled by food type
  Row filled by food name
"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data['food_name']
).sample(11, axis=1).sample(10, axis=0)

# Determining cosine similarity on tf-idf matrix
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Creating new dataframe from `cosine_sim` with rows and columns as food_name
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['food_name'], columns=data['food_name'])
print('Shape:', cosine_sim_df.shape)

# Checking similarity matrix on each food
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def food_recommendations(food_name, similarity_data=cosine_sim_df, items=data[['food_name', 'category']], k=5):
  # Fetch data by using argpartition for indirectly partition along the given axis
  index = similarity_data.loc[:,food_name].to_numpy().argpartition(range(-1, -k, -1))

  # Pick data with greatest similarity from the existing index
  closest = similarity_data.columns[index[-1:-(k+2):-1]]

  # Drop `food_name` so that the searched food name is not appear in the recommendation result
  closest = closest.drop(food_name, errors='ignore')

  return pd.DataFrame(closest).merge(items).head(k)

data[data['food_name'].eq('banana chips')]

food_recommendations('banana chips')

"""## **2. Collaborative Filtering**"""

df_ratings

# Changing `User_ID` to list without same value
user_ids = df_ratings['User_ID'].unique().tolist()
print('list User_ID: ', user_ids)

# Encoding `User_ID`
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User_ID : ', user_to_user_encoded)

# Encoding process number to `User_ID`
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded number to User_ID: ', user_encoded_to_user)

# Changing `Food_ID` to list without same value
food_ids = df_ratings['Food_ID'].unique().tolist()

# Encoding `Food_ID`
food_to_food_encoded = {x: i for i, x in enumerate(food_ids)}

# Encoding process number to `Food_ID`
food_encoded_to_food = {i: x for i, x in enumerate(food_ids)}

# Mapping `User_ID` to dataframe user
df_ratings['user'] = df_ratings['User_ID'].map(user_to_user_encoded)

# Mapping `Food_ID` to dataframe food
df_ratings['food'] = df_ratings['Food_ID'].map(food_to_food_encoded)

# Check for number of users
num_users = len(user_to_user_encoded)
print(num_users)

# Check for number of foods
num_food = len(food_encoded_to_food)
print(num_food)

# Changing rating into floating numbers
df_ratings['rating'] = df_ratings['Rating'].values.astype(np.float32)

# Minimum value of rating
min_rating = min(df_ratings['rating'])

# Maximum value of rating
max_rating = max(df_ratings['rating'])

print('Number of User: {}, Number of Food: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_food, min_rating, max_rating
    )
)

# Shuffle the dataset
df_ratings = df_ratings.sample(frac=1, random_state=42)
df_ratings

# Creating `x` variable to match user and food data into one value
x = df_ratings[['user', 'food']].values

# Creating `y` variable to make rating from the result
y = df_ratings['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Data splitting into 80% training set and 20% validation set
train_indices = int(0.8 * df_ratings.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

class RecommenderNet(tf.keras.Model):
  def __init__(self, num_users, num_food, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_food = num_food
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.food_embedding = layers.Embedding( # layer embeddings food
        num_food,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.food_bias = layers.Embedding(num_food, 1) # layer embedding food bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # calling first embedding layer
    user_bias = self.user_bias(inputs[:, 0]) # calling second embedding layer
    food_vector = self.food_embedding(inputs[:, 1]) # calling third embedding layer
    food_bias = self.food_bias(inputs[:, 1]) # calling fourth embedding layer

    dot_user_food = tf.tensordot(user_vector, food_vector, 2)

    x = dot_user_food + user_bias + food_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_food, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Training process

history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=9,
    epochs=50,
    validation_data=(x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='best')
plt.show()

food_df = food_new
df = pd.read_csv('ratings.csv')

user_id = df['User_ID'].sample(1).iloc[0]
food_tasted_by_user = df[df['User_ID'] == user_id]

food_not_tasted = food_df[~food_df['id'].isin(food_tasted_by_user['Food_ID'].values)]['id']
food_not_tasted = list(
    set(food_not_tasted)
    .intersection(set(food_to_food_encoded.keys()))
)

food_not_tasted = [[food_to_food_encoded.get(x)] for x in food_not_tasted]
food_not_tasted
user_encoder = user_to_user_encoded.get(user_id)
user_food_array = np.hstack(
    ([[user_encoder]] * len(food_not_tasted), food_not_tasted)
)

ratings = model.predict(user_food_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_food_ids = [food_encoded_to_food.get(food_not_tasted[x][0]) for x in top_ratings_indices]

print('Showing recommendations for users: {}'.format(int(user_id)))
print('===' * 9)
print('Food with high ratings from user')
print('----' * 8)

top_food_user = (
    food_tasted_by_user.sort_values(
        by='Rating',
        ascending=False
    )
    .head(5)
    .Food_ID.values
)

food_df_rows = food_df[food_df['id'].isin(top_food_user)]
for row in food_df_rows.itertuples():
  print(row.food_name, ':', row.category)

print('----' * 8)
print('Top 10 food recommendation')
print('----' * 8)

recommended_food = food_df[food_df['id'].isin(recommended_food_ids)]
for row in recommended_food.itertuples():
  print(row.food_name, ':', row.category)

